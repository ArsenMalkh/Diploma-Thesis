{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba047b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "markup_folder_path = \"/home/devel/NVI/outputs/my_notebook/markup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fe5e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.8/dist-packages (1.6.5)\n",
      "Collecting ipdb\n",
      "  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
      "Collecting ipymarkup\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting razdel\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2.6.0)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.3.2)\n",
      "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.12.0+cu116)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.19.5)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.0)\n",
      "Collecting PyYAML>=5.4\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (3.9.2)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.11.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.5.0)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.8/dist-packages (from ipdb) (2.0.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipdb) (5.1.0)\n",
      "Collecting ipython>=7.31.1\n",
      "  Downloading ipython-8.12.2-py3-none-any.whl (797 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.8/797.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting intervaltree>=3\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.28.2)\n",
      "Collecting sortedcontainers<3.0,>=2.0\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.18.0)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.1.3)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
      "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
      "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting stack-data\n",
      "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (2.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf<=3.20.1->pytorch_lightning) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf<=3.20.1->pytorch_lightning) (45.2.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (2.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.34.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.31.1->ipdb) (0.2.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.12.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (22.2.0)\n",
      "Collecting executing>=1.2.0\n",
      "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
      "Collecting pure-eval\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
      "Building wheels for collected packages: intervaltree\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26102 sha256=cba7aea4d1e9478fefa5af2cd6af44842b8fc616f99731a0812661fa3a9b1cfe\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/23/de/5789a92962483fd33cb06674792b9697c1b3766d7c7742830e\n",
      "Successfully built intervaltree\n",
      "Installing collected packages: sortedcontainers, razdel, pure-eval, executing, PyYAML, prompt-toolkit, intervaltree, asttokens, stack-data, ipymarkup, ipython, ipdb\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.3.1\n",
      "\u001b[31mERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting torchmetrics==0.10.3\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics==0.10.3) (21.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics==0.10.3) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics==0.10.3) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics==0.10.3) (1.12.0+cu116)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics==0.10.3) (2.4.7)\n",
      "Installing collected packages: torchmetrics\n",
      "  Attempting uninstall: torchmetrics\n",
      "    Found existing installation: torchmetrics 0.11.1\n",
      "    Uninstalling torchmetrics-0.11.1:\n",
      "      Successfully uninstalled torchmetrics-0.11.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 1.6.5 requires PyYAML>=5.4, but you have pyyaml 5.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torchmetrics-0.10.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install pytorch_lightning ipdb ipymarkup razdel\n",
    "!sudo pip install torchmetrics==0.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc2da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipymarkup\n",
      "  Using cached ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting intervaltree>=3\n",
      "  Using cached intervaltree-3.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from intervaltree>=3->ipymarkup) (2.4.0)\n",
      "Installing collected packages: intervaltree, ipymarkup\n",
      "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (7.28.0)\n",
      "Collecting widgetsnbextension~=4.0.7\n",
      "  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (6.4.1)\n",
      "Collecting jupyterlab-widgets~=3.0.7\n",
      "  Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.2/198.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (45.2.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.8/dist-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.0.6 jupyterlab-widgets-3.0.7 widgetsnbextension-4.0.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install ipymarkup\n",
    "!sudo pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d51a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from xml.etree import ElementTree\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, namedtuple\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from enum import IntEnum\n",
    "from razdel import tokenize\n",
    "from ipymarkup import show_box_markup\n",
    "from ipymarkup.palette import palette, BLUE, RED, GREEN, PURPLE, BROWN\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, namedtuple\n",
    "from enum import IntEnum\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics import Accuracy\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ac1e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_annotation(start, end, child, node_id):\n",
    "  dct = defaultdict(list)\n",
    "  for annotations in child:\n",
    "    if 'annotation' in annotations.tag and \"PropertyAnnotation\" in annotations[0].tag:\n",
    "      property_node_id = [i for i in annotations[0][2].attrib.values()][0]\n",
    "      if property_node_id != node_id:\n",
    "        continue\n",
    "      property_start = int(annotations[0][0].text)\n",
    "      property_end = int(annotations[0][1].text)\n",
    "      if start <= property_start and property_end <= end:\n",
    "        key = re.findall(r\"#\\w*\", annotations[0][3].text)[0][1:]\n",
    "        dct[key].append([property_start - start, property_end - start])\n",
    "  return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfd13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_dict(file_name):\n",
    "  tree = ElementTree.parse(os.path.join(markup_folder_path, file_name)) \n",
    "  root = tree.getroot()\n",
    "\n",
    "  annotation = {}\n",
    "  for child in root:\n",
    "    if \"TextAnnotations\" in child.tag:\n",
    "      for text_anotations in child:\n",
    "        if 'document_text' in text_anotations.tag:\n",
    "          text = text_anotations.text\n",
    "        else:\n",
    "          if \"InstanceAnnotation\" in text_anotations[0].tag:\n",
    "            start = int(text_anotations[0][0].text)\n",
    "            end = int(text_anotations[0][1].text)\n",
    "            node_id = [i for i in text_anotations[0][2].attrib.values()][0]\n",
    "            dct = get_property_annotation(start, end, child, node_id)\n",
    "            if len(dct) == 0:\n",
    "                continue\n",
    "            annotation[text[start : end]] = dct\n",
    "  return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b6dfe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one million Omani Rials': defaultdict(list,\n",
       "             {'ms_major_amount': [[0, 11]], 'ms_major_currency': [[12, 23]]}),\n",
       " 'RO300\\xa0million': defaultdict(list,\n",
       "             {'ms_major_currency': [[0, 2]], 'ms_major_amount': [[2, 13]]}),\n",
       " 'RO 1826.4\\xa0million': defaultdict(list,\n",
       "             {'ms_major_currency': [[0, 2]], 'ms_major_amount': [[3, 17]]}),\n",
       " 'RO50\\xa0million': defaultdict(list,\n",
       "             {'ms_major_currency': [[0, 2]], 'ms_major_amount': [[2, 12]]}),\n",
       " 'RO10\\xa0million': defaultdict(list,\n",
       "             {'ms_major_currency': [[0, 2]], 'ms_major_amount': [[2, 12]]})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_annotation_dict(\"3373424.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7de89e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 6264/6264 [00:01<00:00, 4858.89it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for file in tqdm(os.listdir(markup_folder_path)):\n",
    "  if '.xml' not in file:\n",
    "    continue\n",
    "  annotation = get_annotation_dict(file)\n",
    "  for key, value in annotation.items():\n",
    "    lst = []\n",
    "    for cls, intervals in value.items():\n",
    "      for interval in intervals:\n",
    "        lst.append((interval[0], interval[1], cls))\n",
    "    data.append((key, lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "608f0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenize(text):\n",
    "    tokenized = list(tokenize(text))\n",
    "    pattern = r\"([-_MT€$₽£¥₣₹￠₫])\"\n",
    "    new_tokens = []\n",
    "    for token in tokenized:\n",
    "        annotations = list(filter(None, re.split(pattern, token.text)))\n",
    "        start = token.start\n",
    "        for annot in annotations:\n",
    "            token_annot = list(tokenize(annot))\n",
    "            token_annot[0].start = start\n",
    "            token_annot[0].stop = start + len(annot)\n",
    "            start += len(annot)\n",
    "            new_tokens.append(token_annot[0])\n",
    "    # merge same near symbols\n",
    "    i = 0\n",
    "    while(True):\n",
    "        if i >= len(new_tokens) - 1:\n",
    "            break\n",
    "        if new_tokens[i].text[-1] == new_tokens[i+1].text[0] and new_tokens[i].stop == new_tokens[i+1].start:\n",
    "            new_tokens[i].text += new_tokens[i+1].text\n",
    "            new_tokens[i].stop = new_tokens[i+1].stop\n",
    "            new_tokens.pop(i+1)\n",
    "            i -= 1\n",
    "        i += 1\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "24ce4fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 1, '₹'), Substring(1, 4, 'one')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tokenize(\"₹one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fa3a471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Euro<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">1.6710<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Label.MAJOR_CURRENCY: 2>, <Label.MAJOR_AMOUNT: 1>]\n",
      "17210\n"
     ]
    }
   ],
   "source": [
    "class Label(IntEnum):\n",
    "    MAJOR_AMOUNT = 1\n",
    "    MAJOR_CURRENCY = 2\n",
    "    MINOR_AMOUNT = 3\n",
    "    MINOR_CURRENCY = 4\n",
    "    AMOUNT_BRACKETED = 5\n",
    "    LIKE_BRACKETS = 6\n",
    "\n",
    "Sample = namedtuple(\"Sample\",\"text,tokens,spans,labels\")\n",
    "\n",
    "def text_span_to_sample(text, spans):\n",
    "  labels = []\n",
    "  tokens = my_tokenize(text)\n",
    "  for token in tokens:\n",
    "        label = Label.LIKE_BRACKETS\n",
    "        for span in spans:\n",
    "            span_begin, span_end, tag = span\n",
    "            if token.start >= span_begin and token.stop <= span_end:\n",
    "                if tag == 'ms_major_amount':\n",
    "                  label = Label.MAJOR_AMOUNT\n",
    "                elif tag == 'ms_major_currency':\n",
    "                  label = Label.MAJOR_CURRENCY\n",
    "                elif tag == 'ms_minor_amount':\n",
    "                  label = Label.MINOR_AMOUNT\n",
    "                elif tag == 'ms_minor_currency':\n",
    "                  label = Label.MINOR_CURRENCY\n",
    "                elif tag == 'ms_major_amount_bracketed':\n",
    "                  label = Label.AMOUNT_BRACKETED          \n",
    "        labels.append(label)\n",
    "  return Sample(text, tokens, spans, labels)\n",
    "\n",
    "samples = []\n",
    "for text, spans in data:\n",
    "    samples.append(text_span_to_sample(text, spans))\n",
    "\n",
    "show_box_markup(samples[8683].text, samples[8683].spans, palette=palette(ms_major_currency=BLUE, ms_major_amount=RED, ms_minor_amount=GREEN, ms_minor_currency=PURPLE, ms_major_amount_bracketed=BROWN))\n",
    "print(samples[8683].labels)\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b9b77953",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(samples)\n",
    "\n",
    "train = samples[:11500]\n",
    "val = samples[11500:13500]\n",
    "test = samples[13500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a3a01035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('input/train1.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    for index in range(len(train)):\n",
    "        for token_index in range(len(train[index].tokens)):\n",
    "            tsv_writer.writerow([train[index].tokens[token_index].text, train[index].labels[token_index].name])\n",
    "        tsv_writer.writerow(['', ''])\n",
    "\n",
    "with open('input/test1.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    for index in range(len(test)):\n",
    "        for token_index in range(len(test[index].tokens)):\n",
    "            tsv_writer.writerow([test[index].tokens[token_index].text, test[index].labels[token_index].name])\n",
    "        tsv_writer.writerow(['', ''])\n",
    "\n",
    "with open('input/val1.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    for index in range(len(val)):\n",
    "        for token_index in range(len(val[index].tokens)):\n",
    "            tsv_writer.writerow([val[index].tokens[token_index].text, val[index].labels[token_index].name])\n",
    "        tsv_writer.writerow(['', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a3184050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<unk>', '1', '₤', 'i', 'd', 'ő', 'F', '/', 'ą', 'м', 'م', 'j', 'o', '2', '￦', '₡', '7', 'ê', '5', '£', 'ó', 'á', '¢', '¼', 'Z', 'z', 'e', 'п', ',', '₪', 'h', '9', 'u', 'f', '₧', '¾', '￡', 'E', 'N', 'w', 'm', '\"', 'v', '₭', 't', '₵', 'J', 'y', 'W', 'X', 'ì', 'ł', 'g', 'ƒ', '⁄', 'U', 'đ', '₽', 'ر', '฿', '_', '₹', '₱', 'ع', 'c', 'a', 'l', '¥', 'V', '₺', 'ā', ']', 'ø', '$', '₾', 'ạ', 'с', 'L', 'n', '₯', 'S', '4', 'к', '€', 'q', 'ý', 'ä', '(', '½', '6', '0', '”', 'C', 'A', '·', '₫', 'í', '\\u200b', 'B', 'k', ')', 'O', '.', 'ồ', '₼', 'ö', 'é', 'ề', '₮', 'p', '“', '’', '+', \"'\", 'ل', 'x', '₴', 'R', '-', '[', '3', '￥', 'Y', 'P', 'о', '៛', 'b', '⅛', '8', 'M', 's', 'Q', 'I', 'K', 'r', 'H', '₦', 'D', ':', 'T', 'G', 'د', '৳', '₩', '₨']\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "char_set = [\"<pad>\", \"<unk>\"] + list({ch for sample in train for token in sample.tokens for ch in token.text})\n",
    "print(char_set)\n",
    "print(len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f71fc718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sixty-Three Billion Five Hundred Sixty Million Eight Hundred Thirty-Seven Thousand Two Hundred Sixty-Nine South Korean Won\n",
      "\n",
      "1,200,000,000,000,000,000,000\n",
      "1.2 sextillion (1,200,000,000,000,000,000,000)\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 0\n",
    "max_char_seq_len = 0\n",
    "\n",
    "for sample in samples:\n",
    "  max_seq_len = max(len(sample.tokens), max_seq_len)\n",
    "  if len(sample.tokens) == 27:\n",
    "    print(sample.text)\n",
    "    print()\n",
    "  for token in sample.tokens:\n",
    "    max_char_seq_len = max(len(token.text), max_char_seq_len)\n",
    "    if len(token.text) == 29:\n",
    "        print(token.text)\n",
    "        print(sample.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "56427ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d46f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchtext==0.6.0 in /home/devel/.local/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (4.64.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (1.12.0+cu116)\n",
      "Requirement already satisfied: sentencepiece in /home/devel/.local/lib/python3.8/site-packages (from torchtext==0.6.0) (0.1.99)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.6.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.6.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb0c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pytorch-crf\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5230313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#import gensim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchtext.data import Field, NestedField, BucketIterator\n",
    "from torchtext.datasets import SequenceTaggingDataset\n",
    "from torchtext.vocab import Vocab\n",
    "from torchcrf import CRF\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "bd814d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "\n",
    "    def __init__(self, input_folder, min_word_freq, batch_size, wv_file=None):\n",
    "        # list all the fields\n",
    "        self.word_field = Field(lower=True)  # [sent len, batch_size]\n",
    "        self.tag_field = Field(unk_token=None)  # [sent len, batch_size]\n",
    "        # Character-level input\n",
    "        self.char_nesting_field = Field(tokenize=list)\n",
    "        self.char_field = NestedField(self.char_nesting_field)  # [batch_size, sent len, max len char]\n",
    "        # create dataset using built-in parser from torchtext\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = SequenceTaggingDataset.splits(\n",
    "            path=input_folder,\n",
    "            train=\"train1.tsv\",\n",
    "            validation=\"val1.tsv\",\n",
    "            test=\"test1.tsv\",\n",
    "            fields=(\n",
    "                ((\"word\", \"char\"), (self.word_field, self.char_field)),\n",
    "                (\"tag\", self.tag_field)\n",
    "            )\n",
    "        )\n",
    "        # convert fields to vocabulary list\n",
    "        self.word_field.build_vocab(self.train_dataset.word, min_freq=min_word_freq)\n",
    "        # build vocab for tag and characters\n",
    "        self.char_field.build_vocab(self.train_dataset.char)\n",
    "        self.tag_field.build_vocab(self.train_dataset.tag)\n",
    "        # create iterator for batch input\n",
    "        self.train_iter, self.val_iter, self.test_iter = BucketIterator.splits(\n",
    "            datasets=(self.train_dataset, self.val_dataset, self.test_dataset),\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        # prepare padding index to be ignored during model training/evaluation\n",
    "        self.word_pad_idx = self.word_field.vocab.stoi[self.word_field.pad_token]\n",
    "        self.char_pad_idx = self.char_field.vocab.stoi[self.char_field.pad_token]\n",
    "        self.tag_pad_idx = self.tag_field.vocab.stoi[self.tag_field.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "41d9a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus('/home/devel/NVI/outputs/my_notebook/input/', 1, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b083c99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': ['pound', 'sterling', '185,563.50'],\n",
       " 'char': [['p', 'o', 'u', 'n', 'd'],\n",
       "  ['s', 't', 'e', 'r', 'l', 'i', 'n', 'g'],\n",
       "  ['1', '8', '5', ',', '5', '6', '3', '.', '5', '0']],\n",
       " 'tag': ['MAJOR_CURRENCY', 'MAJOR_CURRENCY', 'MAJOR_AMOUNT']}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train_dataset[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d2928838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 char_emb_dim,\n",
    "                 char_input_dim,\n",
    "                 char_cnn_filter_num,\n",
    "                 char_cnn_kernel_size,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 lstm_layers,\n",
    "                 attn_heads,\n",
    "                 emb_dropout,\n",
    "                 cnn_dropout,\n",
    "                 lstm_dropout,\n",
    "                 attn_dropout,\n",
    "                 fc_dropout,\n",
    "                 word_pad_idx,  # NEWLY ADDED\n",
    "                 char_pad_idx,\n",
    "                 tag_pad_idx):\n",
    "        super().__init__()\n",
    "        self.char_pad_idx = char_pad_idx  # NEWLY ADDED\n",
    "        self.word_pad_idx = word_pad_idx  # NEWLY ADDED\n",
    "        self.tag_pad_idx = tag_pad_idx  # NEWLY ADDED\n",
    "        # LAYER 1A: Word Embedding\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=word_pad_idx\n",
    "        )\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
    "        # LAYER 1B: Char Embedding-CNN\n",
    "        self.char_emb_dim = char_emb_dim\n",
    "        self.char_emb = nn.Embedding(\n",
    "            num_embeddings=char_input_dim,\n",
    "            embedding_dim=char_emb_dim,\n",
    "            padding_idx=char_pad_idx\n",
    "        )\n",
    "        self.char_cnn = nn.Conv1d(\n",
    "            in_channels=char_emb_dim,\n",
    "            out_channels=char_emb_dim * char_cnn_filter_num,\n",
    "            kernel_size=char_cnn_kernel_size,\n",
    "            groups=char_emb_dim  # different 1d conv for each embedding dim\n",
    "        )\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "        # LAYER 2: BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim + (char_emb_dim * char_cnn_filter_num),\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=lstm_dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        # LAYER 3: Self-attention\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim * 2,\n",
    "            num_heads=attn_heads,\n",
    "            dropout=attn_dropout\n",
    "        )\n",
    "        # LAYER 4: Fully-connected\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # times 2 for bidirectional\n",
    "        # LAYER 5: CRF\n",
    "        self.crf = CRF(num_tags=output_dim)\n",
    "        # init weights from normal distribution\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "\n",
    "    def forward(self, words, chars, tags=None):\n",
    "        # words = [sentence length, batch size]\n",
    "        # chars = [batch size, sentence length, word length)\n",
    "        # tags = [sentence length, batch size]\n",
    "        # embedding_out = [sentence length, batch size, embedding dim]\n",
    "        embedding_out = self.emb_dropout(self.embedding(words))\n",
    "        # character cnn layer forward\n",
    "        # reference: https://github.com/achernodub/targer/blob/master/src/layers/layer_char_cnn.py\n",
    "        # char_emb_out = [batch size, sentence length, word length, char emb dim]\n",
    "        char_emb_out = self.emb_dropout(self.char_emb(chars))\n",
    "        batch_size, sent_len, word_len, char_emb_dim = char_emb_out.shape\n",
    "        char_cnn_max_out = torch.zeros(batch_size, sent_len, self.char_cnn.out_channels)\n",
    "        for sent_i in range(sent_len):\n",
    "            # sent_char_emb = [batch size, word length, char emb dim]\n",
    "            sent_char_emb = char_emb_out[:, sent_i, :, :]\n",
    "            # sent_char_emb_p = [batch size, char emb dim, word length]\n",
    "            sent_char_emb_p = sent_char_emb.permute(0, 2, 1)\n",
    "            # char_cnn_sent_out = [batch size, out channels * char emb dim, word length - kernel size + 1]\n",
    "            char_cnn_sent_out = self.char_cnn(sent_char_emb_p)\n",
    "            char_cnn_max_out[:, sent_i, :], _ = torch.max(char_cnn_sent_out, dim=2)\n",
    "        char_cnn = self.cnn_dropout(char_cnn_max_out)\n",
    "        # concat word and char embedding\n",
    "        # char_cnn_p = [sentence length, batch size, char emb dim * num filter]\n",
    "        char_cnn_p = char_cnn.permute(1, 0, 2)\n",
    "        word_features = torch.cat((embedding_out, char_cnn_p), dim=2)\n",
    "        # lstm_out = [sentence length, batch size, hidden dim * 2]\n",
    "        lstm_out, _ = self.lstm(word_features)\n",
    "        ### BEGIN MODIFIED SECTION: ATTENTION ###\n",
    "        # create masking for paddings\n",
    "        # key_padding_mask = [batch size, sentence length]\n",
    "        key_padding_mask = torch.as_tensor(words == self.word_pad_idx).permute(1, 0)\n",
    "        # attn_out = [sentence length, batch size, hidden dim * 2]\n",
    "        # attn_weight = [batch size, sentence length, sentence length]\n",
    "        attn_out, attn_weight = self.attn(lstm_out, lstm_out, lstm_out, key_padding_mask=key_padding_mask)\n",
    "        # fc_out = [sentence length, batch size, output dim]\n",
    "        fc_out = self.fc(self.fc_dropout(attn_out))\n",
    "        crf_mask = words != self.word_pad_idx\n",
    "        crf_out = self.crf.decode(fc_out, mask=crf_mask)\n",
    "        crf_loss = -self.crf(fc_out, tags=tags, mask=crf_mask) if tags is not None else None\n",
    "        return crf_out, crf_loss, attn_weight\n",
    "        ### END MODIFIED SECTION: ATTENTION ###\n",
    "\n",
    "    def init_embeddings(self, char_pad_idx, word_pad_idx, pretrained=None, freeze=True):\n",
    "        # initialize embedding for padding as zero\n",
    "        self.embedding.weight.data[word_pad_idx] = torch.zeros(self.embedding_dim)\n",
    "        self.char_emb.weight.data[char_pad_idx] = torch.zeros(self.char_emb_dim)\n",
    "        if pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embeddings=torch.as_tensor(pretrained),\n",
    "                padding_idx=word_pad_idx,\n",
    "                freeze=freeze\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e890bdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.char_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d1f34c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,174,184 trainable parameters.\n",
      "BiLSTM(\n",
      "  (embedding): Embedding(5841, 300, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (char_emb): Embedding(146, 25, padding_idx=1)\n",
      "  (char_cnn): Conv1d(25, 125, kernel_size=(3,), stride=(1,), groups=25)\n",
      "  (cnn_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (lstm): LSTM(425, 64, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=7, bias=True)\n",
      "  (crf): CRF(num_tags=7)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTM(\n",
    "    input_dim=len(corpus.word_field.vocab),\n",
    "    embedding_dim=300,\n",
    "    char_emb_dim=25,\n",
    "    char_input_dim=len(corpus.char_field.vocab),\n",
    "    char_cnn_filter_num=5,\n",
    "    char_cnn_kernel_size=3,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(corpus.tag_field.vocab),\n",
    "    lstm_layers=2,\n",
    "    attn_heads=16,\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    lstm_dropout=0.1,\n",
    "    attn_dropout=0.25,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=corpus.word_pad_idx,\n",
    "    char_pad_idx=corpus.char_pad_idx,\n",
    "    tag_pad_idx=corpus.tag_pad_idx\n",
    ")\n",
    "bilstm.init_embeddings(\n",
    "    char_pad_idx=corpus.char_pad_idx,\n",
    "    word_pad_idx=corpus.word_pad_idx,\n",
    "    pretrained = None,\n",
    "    freeze=True\n",
    ")\n",
    "\n",
    "\n",
    "print(bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "921a7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, model, data, optimizer_cls, loss_fn_cls):\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.optimizer = optimizer_cls(model.parameters())\n",
    "        self.loss_fn = loss_fn_cls(ignore_index=self.data.tag_pad_idx)\n",
    "\n",
    "    @staticmethod\n",
    "    def epoch_time(start_time, end_time):\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs\n",
    "\n",
    "    def accuracy(self, preds, y):\n",
    "        flatten_preds = [pred for sent_pred in preds for pred in sent_pred]\n",
    "        flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
    "        correct = [pred == tag for pred, tag in zip(flatten_preds, flatten_y)]\n",
    "        return sum(correct) / len(correct) if len(correct) > 0 else 0\n",
    "\n",
    "    def epoch(self):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        self.model.train()\n",
    "        for batch in self.data.train_iter:\n",
    "            # words = [sent len, batch size]\n",
    "            words = batch.word\n",
    "            # chars = [batch size, sent len, char len]\n",
    "            chars = batch.char\n",
    "            # tags = [sent len, batch size]\n",
    "            true_tags = batch.tag\n",
    "            self.optimizer.zero_grad()\n",
    "            pred_tags_list, batch_loss, _ = self.model(words, chars, true_tags)\n",
    "            true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != self.data.tag_pad_idx]\n",
    "                for sent_tag in true_tags.permute(1, 0).tolist()\n",
    "            ]\n",
    "            batch_acc = self.accuracy(pred_tags_list, true_tags_list)\n",
    "            batch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            epoch_loss += batch_loss.item()\n",
    "            epoch_acc += batch_acc\n",
    "        return epoch_loss / len(self.data.train_iter), epoch_acc / len(self.data.train_iter)\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in iterator:\n",
    "                words = batch.word\n",
    "                chars = batch.char\n",
    "                true_tags = batch.tag\n",
    "                pred_tags, batch_loss, _ = self.model(words, chars, true_tags)\n",
    "                true_tags_list = [\n",
    "                    [tag for tag in sent_tag if tag != self.data.tag_pad_idx]\n",
    "                    for sent_tag in true_tags.permute(1, 0).tolist()\n",
    "                ]\n",
    "                batch_acc = self.accuracy(pred_tags, true_tags_list)\n",
    "                epoch_loss += batch_loss.item()\n",
    "                epoch_acc += batch_acc\n",
    "        return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        for epoch in range(n_epochs):\n",
    "            start_time = time.time()\n",
    "            train_loss, train_acc = self.epoch()\n",
    "            end_time = time.time()\n",
    "            epoch_mins, epoch_secs = Trainer.epoch_time(start_time, end_time)\n",
    "            print(f\"Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "            print(f\"\\tTrn Loss: {train_loss:.3f} | Trn Acc: {train_acc * 100:.2f}%\")\n",
    "            val_loss, val_acc = self.evaluate(self.data.val_iter)\n",
    "            print(f\"\\tVal Loss: {val_loss:.3f} | Val Acc: {val_acc * 100:.2f}%\")\n",
    "        test_loss, test_acc = self.evaluate(self.data.test_iter)\n",
    "        print(f\"Test Loss: {test_loss:.3f} |  Test Acc: {test_acc * 100:.2f}%\")\n",
    "\n",
    "    def infer(self, sentence, true_tags=None):\n",
    "        self.model.eval()\n",
    "        # tokenize sentence\n",
    "        tokens = [token.text for token in my_tokenize(sentence)]\n",
    "        max_word_len = max([len(token) for token in tokens])\n",
    "        max_word_len = max(3, max_word_len)\n",
    "        # transform to indices based on corpus vocab\n",
    "        numericalized_tokens = [self.data.word_field.vocab.stoi[token.lower()] for token in tokens]\n",
    "        numericalized_chars = []\n",
    "        char_pad_id = self.data.char_pad_idx\n",
    "        for token in tokens:\n",
    "            numericalized_chars.append(\n",
    "                [self.data.char_field.vocab.stoi[char] for char in token]\n",
    "                + [char_pad_id for _ in range(max_word_len - len(token))]\n",
    "            )\n",
    "        # find unknown words\n",
    "        unk_idx = self.data.word_field.vocab.stoi[self.data.word_field.unk_token]\n",
    "        unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "        # begin prediction\n",
    "        token_tensor = torch.as_tensor(numericalized_tokens)\n",
    "        token_tensor = token_tensor.unsqueeze(-1)\n",
    "        char_tensor = torch.as_tensor(numericalized_chars)\n",
    "        char_tensor = char_tensor.unsqueeze(0)\n",
    "        predictions, _, attn_weight = self.model(token_tensor, char_tensor)  # NEWLY ADDED\n",
    "        #Trainer.visualize_attn(tokens, attn_weight.detach().numpy()[0])  # NEWLY ADDED\n",
    "        # convert results to tags\n",
    "        predicted_tags = [self.data.tag_field.vocab.itos[t] for t in predictions[0]]\n",
    "        # print inferred tags\n",
    "        max_len_token = max([len(token) for token in tokens] + [len('word')])\n",
    "        max_len_tag = max([len(tag) for tag in predicted_tags] + [len('pred')])\n",
    "#         print(\n",
    "#             f\"{'word'.ljust(max_len_token)}\\t{'unk'.ljust(max_len_token)}\\t{'pred tag'.ljust(max_len_tag)}\"\n",
    "#             + (\"\\ttrue tag\" if true_tags else \"\")\n",
    "#         )\n",
    "#         for i, token in enumerate(tokens):\n",
    "#             is_unk = \"✓\" if token in unks else \"\"\n",
    "#             print(\n",
    "#                 f\"{token.ljust(max_len_token)}\\t{is_unk.ljust(max_len_token)}\\t{predicted_tags[i].ljust(max_len_tag)}\"\n",
    "#                 + (f\"\\t{true_tags[i]}\" if true_tags else \"\")\n",
    "#             )\n",
    "        return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "da0f0bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.069 | Trn Acc: 99.98%\n",
      "\tVal Loss: 2.994 | Val Acc: 99.72%\n",
      "Epoch: 02 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.010 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.470 | Val Acc: 99.81%\n",
      "Epoch: 03 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.026 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.030 | Val Acc: 99.79%\n",
      "Epoch: 04 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.170 | Trn Acc: 99.96%\n",
      "\tVal Loss: 1.738 | Val Acc: 99.80%\n",
      "Epoch: 05 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.019 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.183 | Val Acc: 99.74%\n",
      "Epoch: 06 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.007 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.122 | Val Acc: 99.78%\n",
      "Epoch: 07 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.005 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.565 | Val Acc: 99.77%\n",
      "Epoch: 08 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.052 | Trn Acc: 99.98%\n",
      "\tVal Loss: 2.321 | Val Acc: 99.75%\n",
      "Epoch: 09 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.324 | Trn Acc: 99.93%\n",
      "\tVal Loss: 2.083 | Val Acc: 99.74%\n",
      "Epoch: 10 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.032 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.961 | Val Acc: 99.79%\n",
      "Epoch: 11 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.013 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.619 | Val Acc: 99.80%\n",
      "Epoch: 12 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.012 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.819 | Val Acc: 99.76%\n",
      "Epoch: 13 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.063 | Trn Acc: 99.97%\n",
      "\tVal Loss: 2.060 | Val Acc: 99.82%\n",
      "Epoch: 14 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.024 | Trn Acc: 99.98%\n",
      "\tVal Loss: 2.942 | Val Acc: 99.75%\n",
      "Epoch: 15 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.079 | Trn Acc: 99.98%\n",
      "\tVal Loss: 1.948 | Val Acc: 99.81%\n",
      "Epoch: 16 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.020 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.015 | Val Acc: 99.79%\n",
      "Epoch: 17 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.045 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.625 | Val Acc: 99.82%\n",
      "Epoch: 18 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.048 | Trn Acc: 99.98%\n",
      "\tVal Loss: 1.335 | Val Acc: 99.79%\n",
      "Epoch: 19 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.001 | Trn Acc: 100.00%\n",
      "\tVal Loss: 1.457 | Val Acc: 99.79%\n",
      "Epoch: 20 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.003 | Trn Acc: 100.00%\n",
      "\tVal Loss: 1.896 | Val Acc: 99.78%\n",
      "Epoch: 21 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.017 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.886 | Val Acc: 99.78%\n",
      "Epoch: 22 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.028 | Trn Acc: 99.98%\n",
      "\tVal Loss: 2.136 | Val Acc: 99.84%\n",
      "Epoch: 23 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.027 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.012 | Val Acc: 99.82%\n",
      "Epoch: 24 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.012 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.721 | Val Acc: 99.78%\n",
      "Epoch: 25 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.006 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.093 | Val Acc: 99.83%\n",
      "Epoch: 26 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.011 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.078 | Val Acc: 99.84%\n",
      "Epoch: 27 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.000 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.251 | Val Acc: 99.86%\n",
      "Epoch: 28 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.026 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.170 | Val Acc: 99.84%\n",
      "Epoch: 29 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.000 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.316 | Val Acc: 99.83%\n",
      "Epoch: 30 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.000 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.389 | Val Acc: 99.85%\n",
      "Epoch: 31 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.049 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.343 | Val Acc: 99.84%\n",
      "Epoch: 32 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.013 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.869 | Val Acc: 99.81%\n",
      "Epoch: 33 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.116 | Trn Acc: 99.97%\n",
      "\tVal Loss: 1.614 | Val Acc: 99.86%\n",
      "Epoch: 34 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.036 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.606 | Val Acc: 99.86%\n",
      "Epoch: 35 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.018 | Trn Acc: 100.00%\n",
      "\tVal Loss: 1.459 | Val Acc: 99.86%\n",
      "Epoch: 36 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.017 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.573 | Val Acc: 99.84%\n",
      "Epoch: 37 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.029 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.945 | Val Acc: 99.75%\n",
      "Epoch: 38 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.043 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.847 | Val Acc: 99.75%\n",
      "Epoch: 39 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.003 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.287 | Val Acc: 99.83%\n",
      "Epoch: 40 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.028 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.419 | Val Acc: 99.81%\n",
      "Epoch: 41 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.021 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.972 | Val Acc: 99.78%\n",
      "Epoch: 42 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.004 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.746 | Val Acc: 99.72%\n",
      "Epoch: 43 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.073 | Trn Acc: 99.98%\n",
      "\tVal Loss: 2.631 | Val Acc: 99.79%\n",
      "Epoch: 44 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.001 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.554 | Val Acc: 99.81%\n",
      "Epoch: 45 | Epoch Time: 0m 20s\n",
      "\tTrn Loss: 0.038 | Trn Acc: 99.99%\n",
      "\tVal Loss: 1.668 | Val Acc: 99.81%\n",
      "Epoch: 46 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.000 | Trn Acc: 100.00%\n",
      "\tVal Loss: 1.793 | Val Acc: 99.80%\n",
      "Epoch: 47 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.008 | Trn Acc: 100.00%\n",
      "\tVal Loss: 2.181 | Val Acc: 99.82%\n",
      "Epoch: 48 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.053 | Trn Acc: 99.99%\n",
      "\tVal Loss: 2.428 | Val Acc: 99.79%\n",
      "Epoch: 49 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.068 | Trn Acc: 99.99%\n",
      "\tVal Loss: 3.054 | Val Acc: 99.67%\n",
      "Epoch: 50 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.002 | Trn Acc: 100.00%\n",
      "\tVal Loss: 3.047 | Val Acc: 99.71%\n",
      "Test Loss: 1.932 |  Test Acc: 99.80%\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=bilstm,\n",
    "    data=corpus,\n",
    "    optimizer_cls=Adam,\n",
    "    loss_fn_cls=nn.CrossEntropyLoss  # this is no longer in use, keeping as-is for simplicity\n",
    ")\n",
    "trainer.train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "df387e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [test[index].text for index in range(len(test))]\n",
    "labels = [test[index].labels for index in range(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "95cf3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = []\n",
    "total_infer_tags = []\n",
    "total_true_tags = []\n",
    "for i, sentence in enumerate(sentences):\n",
    "    tags = [label.name for label in labels[i]]\n",
    "    words, infer_tags, unknown_tokens = trainer.infer(sentence=sentence, true_tags=tags)\n",
    "    total_words.append(words)\n",
    "    total_infer_tags.append(torch.tensor([ Label.__members__[tag].value for tag in infer_tags]))\n",
    "    total_true_tags.append(torch.tensor([ Label.__members__[tag].value for tag in tags]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "43b0cb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3,  ..., 2, 2, 1]) tensor([1, 2, 3,  ..., 2, 2, 1])\n",
      "Confusion Matrix\n",
      "\n",
      "[[5392    5    1    0    0    6]\n",
      " [   3 5048    0    0    0    5]\n",
      " [   2    0   20    0    0    0]\n",
      " [   0    2    0   13    0    0]\n",
      " [   0    0    0    0   15    0]\n",
      " [   1    1    0    0    0   41]]\n",
      "\n",
      "Accuracy: 1.00\n",
      "\n",
      "Micro Precision: 1.00\n",
      "Micro Recall: 1.00\n",
      "Micro F1-score: 1.00\n",
      "\n",
      "Macro Precision: 0.96\n",
      "Macro Recall: 0.95\n",
      "Macro F1-score: 0.95\n",
      "\n",
      "Weighted Precision: 1.00\n",
      "Weighted Recall: 1.00\n",
      "Weighted F1-score: 1.00\n",
      "\n",
      "Classification Report\n",
      "\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          ms_major_amount       1.00      1.00      1.00      5404\n",
      "        ms_major_currency       1.00      1.00      1.00      5056\n",
      "          ms_minor_amount       0.95      0.91      0.93        22\n",
      "        ms_minor_currency       1.00      0.87      0.93        15\n",
      "ms_major_amount_bracketed       1.00      1.00      1.00        15\n",
      "      outer_like_brackets       0.79      0.95      0.86        43\n",
      "\n",
      "                 accuracy                           1.00     10555\n",
      "                macro avg       0.96      0.95      0.95     10555\n",
      "             weighted avg       1.00      1.00      1.00     10555\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_111/4198949536.py:38: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10555]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(true_labels, out=all_true_labels)\n",
      "/tmp/ipykernel_111/4198949536.py:39: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10555]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(predicted_labels, out=all_predicted_labels)\n"
     ]
    }
   ],
   "source": [
    "def get_spans(labels, tokens):\n",
    "    spans = []\n",
    "    for i, (label, token) in enumerate(zip(labels, tokens)):\n",
    "        if i != 0 and label == old_label:\n",
    "          spans[-1]= (old_start, token.stop, old_tag)\n",
    "          continue\n",
    "        if label == 1:\n",
    "          spans.append((token.start, token.stop, \"ms_major_amount\"))\n",
    "          tag = \"ms_major_amount\"\n",
    "        elif label == 2:\n",
    "          spans.append((token.start, token.stop, \"ms_major_currency\"))\n",
    "          tag = \"ms_major_currency\"\n",
    "        elif label == 3:\n",
    "          spans.append((token.start, token.stop, \"ms_minor_amount\"))\n",
    "          tag = \"ms_minor_amount\"\n",
    "        elif label == 4:\n",
    "          spans.append((token.start, token.stop, \"ms_minor_currency\"))\n",
    "          tag = \"ms_minor_currency\"\n",
    "        elif label == 5:\n",
    "          spans.append((token.start, token.stop, \"ms_major_amount_bracketed\"))\n",
    "          tag = \"ms_major_amount_bracketed\"\n",
    "        elif label == 6:\n",
    "          spans.append((token.start, token.stop, \"like_brackets\"))\n",
    "          tag = \"like_brackets\"\n",
    "        elif label == 0:\n",
    "          spans.append((token.start, token.stop, \"outer\"))\n",
    "          tag = \"outer\"\n",
    "        old_label = label\n",
    "        old_start = token.start\n",
    "        old_tag = tag\n",
    "    return spans\n",
    "\n",
    "\n",
    "def calc_metrics(true_labels, predicted_labels, tokens):\n",
    "    # Метрики классификации\n",
    "    all_true_labels = torch.tensor((len(test), 27))\n",
    "    all_predicted_labels = torch.tensor((len(test), 27))\n",
    "    torch.cat(true_labels, out=all_true_labels)\n",
    "    torch.cat(predicted_labels, out=all_predicted_labels)\n",
    "    print(all_true_labels, all_predicted_labels)\n",
    "    confusion = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(confusion)\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(all_true_labels, all_predicted_labels)))\n",
    "\n",
    "    print('Micro Precision: {:.2f}'.format(precision_score(all_true_labels, all_predicted_labels, average='micro')))\n",
    "    print('Micro Recall: {:.2f}'.format(recall_score(all_true_labels, all_predicted_labels, average='micro')))\n",
    "    print('Micro F1-score: {:.2f}\\n'.format(f1_score(all_true_labels, all_predicted_labels, average='micro')))\n",
    "\n",
    "    print('Macro Precision: {:.2f}'.format(precision_score(all_true_labels, all_predicted_labels, average='macro')))\n",
    "    print('Macro Recall: {:.2f}'.format(recall_score(all_true_labels, all_predicted_labels, average='macro')))\n",
    "    print('Macro F1-score: {:.2f}\\n'.format(f1_score(all_true_labels, all_predicted_labels, average='macro')))\n",
    "\n",
    "    print('Weighted Precision: {:.2f}'.format(precision_score(all_true_labels, all_predicted_labels, average='weighted')))\n",
    "    print('Weighted Recall: {:.2f}'.format(recall_score(all_true_labels, all_predicted_labels, average='weighted')))\n",
    "    print('Weighted F1-score: {:.2f}'.format(f1_score(all_true_labels, all_predicted_labels, average='weighted')))\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print('\\nClassification Report\\n')\n",
    "    print(classification_report(all_true_labels, all_predicted_labels, target_names=['ms_major_amount', 'ms_major_currency', 'ms_minor_amount', 'ms_minor_currency', 'ms_major_amount_bracketed', 'outer_like_brackets']))\n",
    "\n",
    "    \n",
    "\n",
    "calc_metrics(total_true_tags, total_infer_tags, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fd928dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_false_data(all_true_labels, all_predicted_labels, all_tokens, all_texts):\n",
    "    major_amount_synthetic, major_currency_synthetic, minor_amount_synthetic, minor_currency_synthetic, ms_major_amount_bracketed_sintetic, like_brackets_sintetic, outer_sintetic = [],[],[],[],[],[],[]\n",
    "    cnt = 0\n",
    "    for num in range(len(test)):\n",
    "        eq = torch.all(torch.eq(all_true_labels[num], all_predicted_labels[num]) == True)\n",
    "        if not eq:\n",
    "            cnt +=1\n",
    "            show_box_markup(all_texts[num],\n",
    "                    get_spans(all_predicted_labels[num], all_tokens[num]),\n",
    "                    palette=palette(ms_major_currency=BLUE, ms_major_amount=RED, ms_minor_amount=GREEN, ms_minor_currency=PURPLE, ms_major_amount_bracketed=BROWN))\n",
    "            show_box_markup(all_texts[num],\n",
    "                    get_spans(all_true_labels[num], all_tokens[num]),\n",
    "                    palette=palette(ms_major_currency=BLUE, ms_major_amount=RED, ms_minor_amount=GREEN, ms_minor_currency=PURPLE, ms_major_amount_bracketed=BROWN))\n",
    "            for i, (tr_l, pr_l) in enumerate(zip(all_true_labels[num], all_predicted_labels[num])):\n",
    "                if tr_l != pr_l:\n",
    "                    all_tokens\n",
    "            print()\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f08529f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [my_tokenize(test[num].text) for num in range(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a2aaedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [test[num].text for num in range(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ac7706f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">82 million 1988<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">USD<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">82 million<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">1988 USD<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">4 M<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">io<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">EUR<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">4 Mio<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">EUR<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">BAH<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">T<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">611,000,000<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">BAHT<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">611,000,000<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">GBP l.<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">77<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">GBP<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">l.77<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Ringgit Malaysia<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Three Million Fifty Five            Thousand One Hundred Sixty Three and<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Cents<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Nine<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Ringgit Malaysia<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Three Million Fifty Five            Thousand One Hundred Sixty Three<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">and<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">Cents<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">ms_minor_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">Nine<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">ms_minor_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">1,547,318<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">,952<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">rubles<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">50<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">ms_minor_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">kopeks<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">ms_minor_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">1,547,318 ,952<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">rubles<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">50<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">ms_minor_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">kopeks<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">ms_minor_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">GH¢<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">109,477,926<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">GH¢<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">109,477,926<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">RWF<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">1187<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">mil­lion<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">RWF<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">1187 mil­lion<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">.999<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">-<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">silver<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">two<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">ms_minor_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">new sheqalim<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">.999-silver<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">two<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">new sheqalim<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Rbth<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">121,667<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Rbth<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">121,667<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">MXN<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">(108<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">)<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">MM<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">MXN<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">(108)MM<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">sixpence<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">sixpence<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">EUR<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">1.794<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">milllion<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">EUR<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">1.794 milllion<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">£<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">26 13<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">s<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">£<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">26<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">13<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">ms_minor_amount</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">s<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">ms_minor_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">BAH<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">T<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">600,000,000<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">BAHT<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">600,000,000<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">USD<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">22<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">min<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">like_brackets</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">USD<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">22 min<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$.<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">60<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">U.S.<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">.60<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">U.S.<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Ten Malayan dollars<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Ten<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Malayan dollars<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "false_detection = generate_false_data(total_true_tags, total_infer_tags, all_tokens, all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e6b7339e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e7eee",
   "metadata": {},
   "source": [
    "## Add synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "2c95d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting num2words\n",
      "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting docopt>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=9da196e67ad5558b50c986ea21875e78dc9d7bcb7463b656315df71439bb1a6b\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, num2words\n",
      "Successfully installed docopt-0.6.2 num2words-0.5.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "3fd37b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_major_currency_syntetics = ['1988 USD', 'Malayan dollars', 'BAHT', '.999-silver', '1988 USD', 'GH¢', '']\n",
    "ms_major_amount_syntetics = ['thousand', 'MM', 'min', 'Mio', 'million', '']\n",
    "ms_like_brackets_syntetics = ['(', 'and', '']\n",
    "ms_minor_currency_syntetics = ['kop.', 'quadrans', 's', 'Cents', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a87826b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">thirty four Mio<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ms_major_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">.999-silver<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">ms_major_currency</span></span> (<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d7ccc8; background: #efebe9\">Mio<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #a1887f;\">ms_major_amount_bracketed</span></span>) <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">twenty seven<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">ms_minor_amount</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">quadrans<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">ms_minor_currency</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from num2words import num2words\n",
    "\n",
    "def generate_synthetic_data(ms_major_amount_syntetics, ms_major_currency_syntetics, ms_like_brackets_syntetics, ms_minor_currency_syntetics):\n",
    "  # select ms_major_amount\n",
    "  number = random.randint(1, 100)\n",
    "  number_text = num2words(number).replace('-', ' ')\n",
    "  second_part = random.choice(ms_major_amount_syntetics)\n",
    "  if random.uniform(0, 1) > 0.5:\n",
    "    major_amount = str(number) + second_part\n",
    "  else:\n",
    "    major_amount = number_text + ' ' + second_part\n",
    "  \n",
    "  # select ms_major_currency\n",
    "  major_currency = random.choice(ms_major_currency_syntetics)\n",
    "\n",
    "  # select brackets\n",
    "  outer_like_brackets = random.choice(ms_like_brackets_syntetics)\n",
    "  if outer_like_brackets == '(':\n",
    "    number = random.randint(11, 100)\n",
    "    number_text = num2words(number).replace('-', ' ')\n",
    "    outer_like_brackets += random.choice([number_text, random.choice(ms_major_amount_syntetics[:-1])]) + ')'\n",
    "  elif outer_like_brackets == '[':\n",
    "    number = random.randint(11, 100)\n",
    "    number_text = num2words(number).replace('-', ' ')\n",
    "    outer_like_brackets += random.choice([number_text, random.choice(ms_major_amount_syntetics[:-1])]) + ']'\n",
    "  # select minors\n",
    "  minor_currency = random.choice(ms_minor_currency_syntetics)\n",
    "  if minor_currency == '':\n",
    "    minor_amount = ''\n",
    "  else:\n",
    "    number = random.randint(1, 50)\n",
    "    minor_amount = num2words(number).replace('-', ' ')\n",
    "\n",
    "  anotation_str = \"\"\n",
    "  anotation_list = []\n",
    "  prefix = 0\n",
    "  if major_amount != '':\n",
    "    anotation_str += major_amount\n",
    "    anotation_list.append((0, len(major_amount), 'ms_major_amount'))\n",
    "    prefix = len(major_amount)\n",
    "  if major_currency != '':\n",
    "    anotation_str += ' ' + major_currency\n",
    "    anotation_list.append((prefix + 1, prefix + len(major_currency) + 1, 'ms_major_currency'))\n",
    "    prefix += len(major_currency) + 1\n",
    "\n",
    "  if outer_like_brackets != '':\n",
    "    anotation_str += ' ' + outer_like_brackets\n",
    "    if outer_like_brackets[0] == '(':\n",
    "      anotation_list.append((prefix+2, prefix + len(outer_like_brackets), 'ms_major_amount_bracketed'))\n",
    "    elif outer_like_brackets[0] == '[':\n",
    "      anotation_list.append((prefix+2, prefix + len(outer_like_brackets), 'ms_major_amount_bracketed'))\n",
    "    prefix += len(outer_like_brackets) + 1\n",
    "  \n",
    "  if minor_amount != '':\n",
    "    anotation_str += ' ' + minor_amount\n",
    "    anotation_list.append((prefix + 1, prefix + 1 + len(minor_amount), 'ms_minor_amount'))\n",
    "    prefix += 1 + len(minor_amount)\n",
    "  \n",
    "  if minor_currency != '':\n",
    "    anotation_str += ' ' + minor_currency\n",
    "    anotation_list.append((prefix + 1, prefix + 1 + len(minor_currency), 'ms_minor_currency'))\n",
    "    prefix += 1 + len(minor_currency)\n",
    "\n",
    "  return (anotation_str, anotation_list)\n",
    "\n",
    "synthetic_data = []\n",
    "for _ in range(120):\n",
    "  synthetic_data.append(generate_synthetic_data(ms_major_amount_syntetics, ms_major_currency_syntetics, ms_like_brackets_syntetics, ms_minor_currency_syntetics))\n",
    "\n",
    "show_box_markup(synthetic_data[2][0], synthetic_data[2][1], palette=palette(ms_major_currency=BLUE, ms_major_amount=RED, ms_minor_amount=GREEN, ms_minor_currency=PURPLE, ms_major_amount_bracketed=BROWN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "3acbffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_train = []\n",
    "for text, spans in synthetic_data:\n",
    "    synthetic_train.append(text_span_to_sample(text, spans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "d457a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_synthetic_samples = samples + synthetic_train\n",
    "new_synthetic_train = train + synthetic_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "417d6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input/synthetic_train.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    for index in range(len(new_synthetic_train)):\n",
    "        for token_index in range(len(new_synthetic_train[index].tokens)):\n",
    "            tsv_writer.writerow([new_synthetic_train[index].tokens[token_index].text, new_synthetic_train[index].labels[token_index].name])\n",
    "        tsv_writer.writerow(['', ''])\n",
    "\n",
    "with open('input/synthetic_test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    for index in range(len(test)):\n",
    "        for token_index in range(len(test[index].tokens)):\n",
    "            tsv_writer.writerow([test[index].tokens[token_index].text, test[index].labels[token_index].name])\n",
    "        tsv_writer.writerow(['', ''])\n",
    "\n",
    "with open('input/synthetic_val.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    for index in range(len(val)):\n",
    "        for token_index in range(len(val[index].tokens)):\n",
    "            tsv_writer.writerow([val[index].tokens[token_index].text, val[index].labels[token_index].name])\n",
    "        tsv_writer.writerow(['', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "94e51d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "\n",
    "    def __init__(self, input_folder, min_word_freq, batch_size, wv_file=None):\n",
    "        # list all the fields\n",
    "        self.word_field = Field(lower=True)  # [sent len, batch_size]\n",
    "        self.tag_field = Field(unk_token=None)  # [sent len, batch_size]\n",
    "        # Character-level input\n",
    "        self.char_nesting_field = Field(tokenize=list)\n",
    "        self.char_field = NestedField(self.char_nesting_field)  # [batch_size, sent len, max len char]\n",
    "        # create dataset using built-in parser from torchtext\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = SequenceTaggingDataset.splits(\n",
    "            path=input_folder,\n",
    "            train=\"synthetic_train.tsv\",\n",
    "            validation=\"synthetic_val.tsv\",\n",
    "            test=\"synthetic_test.tsv\",\n",
    "            fields=(\n",
    "                ((\"word\", \"char\"), (self.word_field, self.char_field)),\n",
    "                (\"tag\", self.tag_field)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        # convert fields to vocabulary list\n",
    "        self.word_field.build_vocab(self.train_dataset.word, min_freq=min_word_freq)\n",
    "        # build vocab for tag and characters\n",
    "        self.char_field.build_vocab(self.train_dataset.char)\n",
    "        self.tag_field.build_vocab(self.train_dataset.tag)\n",
    "        # create iterator for batch input\n",
    "        self.train_iter, self.val_iter, self.test_iter = BucketIterator.splits(\n",
    "            datasets=(self.train_dataset, self.val_dataset, self.test_dataset),\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        # prepare padding index to be ignored during model training/evaluation\n",
    "        self.word_pad_idx = self.word_field.vocab.stoi[self.word_field.pad_token]\n",
    "        self.char_pad_idx = self.char_field.vocab.stoi[self.char_field.pad_token]\n",
    "        self.tag_pad_idx = self.tag_field.vocab.stoi[self.tag_field.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "52e7a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_corpus = Corpus('/home/devel/NVI/outputs/my_notebook/input/', 1, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "0290b06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,176,284 trainable parameters.\n",
      "BiLSTM(\n",
      "  (embedding): Embedding(5848, 300, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (char_emb): Embedding(146, 25, padding_idx=1)\n",
      "  (char_cnn): Conv1d(25, 125, kernel_size=(3,), stride=(1,), groups=25)\n",
      "  (cnn_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (lstm): LSTM(425, 64, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=7, bias=True)\n",
      "  (crf): CRF(num_tags=7)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTM(\n",
    "    input_dim=len(synthetic_corpus.word_field.vocab),\n",
    "    embedding_dim=300,\n",
    "    char_emb_dim=25,\n",
    "    char_input_dim=len(synthetic_corpus.char_field.vocab),\n",
    "    char_cnn_filter_num=5,\n",
    "    char_cnn_kernel_size=3,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(synthetic_corpus.tag_field.vocab),\n",
    "    lstm_layers=2,\n",
    "    attn_heads=16,\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    lstm_dropout=0.1,\n",
    "    attn_dropout=0.25,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=synthetic_corpus.word_pad_idx,\n",
    "    char_pad_idx=synthetic_corpus.char_pad_idx,\n",
    "    tag_pad_idx=synthetic_corpus.tag_pad_idx\n",
    ")\n",
    "bilstm.init_embeddings(\n",
    "    char_pad_idx=synthetic_corpus.char_pad_idx,\n",
    "    word_pad_idx=synthetic_corpus.word_pad_idx,\n",
    "    pretrained = None,\n",
    "    freeze=True\n",
    ")\n",
    "\n",
    "print(f\"The model has {bilstm.count_parameters():,} trainable parameters.\")\n",
    "print(bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 20.715 | Trn Acc: 77.80%\n",
      "\tVal Loss: 3.076 | Val Acc: 98.61%\n",
      "Epoch: 02 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 2.702 | Trn Acc: 98.37%\n",
      "\tVal Loss: 1.243 | Val Acc: 99.60%\n",
      "Epoch: 03 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 1.395 | Trn Acc: 99.20%\n",
      "\tVal Loss: 1.130 | Val Acc: 99.58%\n",
      "Epoch: 04 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.709 | Trn Acc: 99.58%\n",
      "\tVal Loss: 0.801 | Val Acc: 99.80%\n",
      "Epoch: 05 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.437 | Trn Acc: 99.77%\n",
      "\tVal Loss: 0.799 | Val Acc: 99.73%\n",
      "Epoch: 06 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.453 | Trn Acc: 99.76%\n",
      "\tVal Loss: 0.731 | Val Acc: 99.78%\n",
      "Epoch: 07 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.234 | Trn Acc: 99.86%\n",
      "\tVal Loss: 1.058 | Val Acc: 99.75%\n",
      "Epoch: 08 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.365 | Trn Acc: 99.79%\n",
      "\tVal Loss: 0.897 | Val Acc: 99.72%\n",
      "Epoch: 09 | Epoch Time: 0m 25s\n",
      "\tTrn Loss: 0.195 | Trn Acc: 99.89%\n",
      "\tVal Loss: 0.794 | Val Acc: 99.84%\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=bilstm,\n",
    "    data=synthetic_corpus,\n",
    "    optimizer_cls=Adam,\n",
    "    loss_fn_cls=nn.CrossEntropyLoss  # this is no longer in use, keeping as-is for simplicity\n",
    ")\n",
    "trainer.train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [test[index].text for index in range(len(test))]\n",
    "labels = [test[index].labels for index in range(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = []\n",
    "total_infer_tags = []\n",
    "total_true_tags = []\n",
    "for i, sentence in enumerate(sentences):\n",
    "    tags = [label.name for label in labels[i]]\n",
    "    words, infer_tags, unknown_tokens = trainer.infer(sentence=sentence, true_tags=tags)\n",
    "    total_words.append(words)\n",
    "    total_infer_tags.append(torch.tensor([ Label.__members__[tag].value for tag in infer_tags]))\n",
    "    total_true_tags.append(torch.tensor([ Label.__members__[tag].value for tag in tags]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_metrics(total_true_tags, total_infer_tags, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7095e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_detection = generate_false_data(total_true_tags, total_infer_tags, all_tokens, all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ca82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78d983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
